{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instructions: run entire notebook after specifying directory variable at the top\n",
    "> model = resnet54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/home/paperspace/Documents/image_splits\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.11.3+cu113'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchvision.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils import data\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from PIL import Image\n",
    "\n",
    "import pprint, pickle\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(dir):\n",
    "    r = []\n",
    "    for root, dirs, files in os.walk(dir):\n",
    "        for name in files:\n",
    "            r.append(os.path.join(root, name))\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "4bd4e024-b1ca-4eb7-adf6-4eb8f9110816",
     "kernelId": "4f378984-b18d-4458-aec5-11036b1449fe"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to /home/paperspace/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# model = models.resnet34(pretrained=True)\n",
    "model = models.resnet152(pretrained=True) # we do not specify pretrained=True, i.e. do not load default weights\n",
    "# model.load_state_dict(torch.load('XNAS/trained_models/xnas_small_cifar10.t7'), strict=False)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 25)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "64b15a06-9d16-4d68-a130-7c6c2d4298ab",
     "kernelId": "4f378984-b18d-4458-aec5-11036b1449fe"
    }
   },
   "outputs": [],
   "source": [
    "def test_model(model, generator):\n",
    "    pbar = tqdm(val_generator)\n",
    "    running_corrects = 0\n",
    "    for step, batch in enumerate(pbar):\n",
    "        model.eval()\n",
    "      # inputs = inputs.to(device)\n",
    "      # labels = labels.to(device)\n",
    "        inputs, labels = batch\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "      # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "      # forward\n",
    "      # track history if only in train\n",
    "      # with torch.set_grad_enabled(phase == 'train'):\n",
    "      \n",
    "    \n",
    "      \n",
    "      #print(tuple(images)[0])\n",
    "      # print(labels)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            # print(preds)\n",
    "      \n",
    "    epoch_acc = running_corrects / len(val)\n",
    "    return epoch_acc.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "5a091f1f-ae6c-4be7-bccc-ed41441e1497",
     "kernelId": "4f378984-b18d-4458-aec5-11036b1449fe"
    }
   },
   "source": [
    "## train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToTensor()"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchvision.transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file):\n",
    "    \"\"\"\n",
    "        given a file, returns generators for training, test, and validation\n",
    "    \"\"\"\n",
    "    \n",
    "    def read_make_image_splits(file):\n",
    "        \"\"\"\n",
    "            given a .pkl file, returns a 3D numpy array\n",
    "        \"\"\"\n",
    "\n",
    "        pkl_file = open(file, 'rb')\n",
    "\n",
    "        data1 = pickle.load(pkl_file)\n",
    "        pkl_file.close()\n",
    "\n",
    "        return data1\n",
    "    \n",
    "    df = pd.DataFrame(read_make_image_splits(file), columns=[\"brand\", \"size\", \"measure\", \"class\", \"long_description\", \"ImageList\", \"image_matrix\"])\n",
    "\n",
    "    df_brand = df[[\"image_matrix\", \"brand\"]]\n",
    "    df_brand[\"image_tensor\"] = df_brand[\"image_matrix\"].map(lambda img: torch.tensor(img))\n",
    "    df_brand.drop(\"image_matrix\", axis=1, inplace=True)\n",
    "    \n",
    "    ske = LabelEncoder()\n",
    "    df_brand[\"brand\"] = ske.fit_transform(df_brand[\"brand\"])\n",
    "    df_brand.Brand = df_brand[\"brand\"].astype(int)\n",
    "\n",
    "    train = list(zip(df_brand[\"image_tensor\"].values, df_brand[\"brand\"].values))\n",
    "    \n",
    "    train, val = train_test_split(train, test_size=0.2)\n",
    "    train, test = train_test_split(train, test_size=0.1)\n",
    "\n",
    "    train_generator = data.DataLoader(train, batch_size=64)\n",
    "    test_generator = data.DataLoader(test, batch_size=64)\n",
    "    val_generator = data.DataLoader(val, batch_size=64)\n",
    "    \n",
    "    return train_generator, test_generator, val_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "cb034852-b0b2-44f4-b06c-fa4521d4ac33",
     "kernelId": "4f378984-b18d-4458-aec5-11036b1449fe"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ToTensor() takes no arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m files \u001b[38;5;241m=\u001b[39m list_files(directory)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[0;32m---> 11\u001b[0m     train_generator, test_generator, val_generator \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, num_epochs))\n",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36mpreprocess\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file)\n\u001b[1;32m      7\u001b[0m df_brand \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBrand\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m----> 8\u001b[0m df_brand[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_brand\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage_matrix\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mToTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m df_brand\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m ske \u001b[38;5;241m=\u001b[39m LabelEncoder()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/series.py:4237\u001b[0m, in \u001b[0;36mSeries.map\u001b[0;34m(self, arg, na_action)\u001b[0m\n\u001b[1;32m   4162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, arg, na_action\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[1;32m   4163\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4164\u001b[0m \u001b[38;5;124;03m    Map values of Series according to an input mapping or function.\u001b[39;00m\n\u001b[1;32m   4165\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4235\u001b[0m \u001b[38;5;124;03m    dtype: object\u001b[39;00m\n\u001b[1;32m   4236\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4238\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_values, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[1;32m   4239\u001b[0m         \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4240\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/base.py:880\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action)\u001b[0m\n\u001b[1;32m    877\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    879\u001b[0m \u001b[38;5;66;03m# mapper is a function\u001b[39;00m\n\u001b[0;32m--> 880\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mmap_f\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_values\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36mpreprocess.<locals>.<lambda>\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file)\n\u001b[1;32m      7\u001b[0m df_brand \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBrand\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m----> 8\u001b[0m df_brand[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df_brand[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m img: \u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mToTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      9\u001b[0m df_brand\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m ske \u001b[38;5;241m=\u001b[39m LabelEncoder()\n",
      "\u001b[0;31mTypeError\u001b[0m: ToTensor() takes no arguments"
     ]
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "best_acc = 0\n",
    "losses = []\n",
    "scores = []\n",
    "best_model_wts = None\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "files = list_files(directory)\n",
    "for file in files:\n",
    "    train_generator, test_generator, val_generator = preprocess(file)\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "        print('-' * 10)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "        pbar = tqdm(train_generator)\n",
    "        running_avg_loss = 0\n",
    "        for step, batch in enumerate(pbar):\n",
    "            model.train()\n",
    "            # inputs = inputs.to(device)\n",
    "            # labels = labels.to(device)\n",
    "            inputs, labels = batch\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            # track history if only in train\n",
    "            # with torch.set_grad_enabled(phase == 'train'):\n",
    "            '''images = []\n",
    "            for image_path in inputs:\n",
    "                img = Image.open(os.path.join(image_dir, image_path))\n",
    "                images.append(transforms.ToTensor()(img))'''\n",
    "\n",
    "            #print(tuple(images)[0])\n",
    "            # print(labels)\n",
    "            outputs = model(inputs)\n",
    "            # _, preds = torch.max(outputs, 1)\n",
    "            loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "\n",
    "            # backward + optimize only if in training phase\n",
    "            loss.backward()\n",
    "            # print(loss)\n",
    "            # pbar.set_description(str(loss.item()))\n",
    "            optimizer.step()\n",
    "            # avg_loss = (avg_loss + loss.item()) / (step + 1)\n",
    "            running_avg_loss += loss.item()\n",
    "            pbar.set_description(\"Avg Loss: \" + str(running_avg_loss / (step + 1)))\n",
    "\n",
    "            # statistics\n",
    "            # running_loss += loss.item() * inputs.size(0)\n",
    "            # running_corrects += torch.sum(preds == labels.data)\n",
    "            # scheduler.step()\n",
    "\n",
    "        epoch_acc = test_model(model, val_generator)\n",
    "        if epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        print(\"validation accuracy:\", epoch_acc)\n",
    "        scores.append(epoch_acc)\n",
    "\n",
    "        losses.append(running_avg_loss / len(train_generator))\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "937a4285-061a-44cf-b15b-8284ea48b336",
     "kernelId": "4f378984-b18d-4458-aec5-11036b1449fe"
    }
   },
   "outputs": [],
   "source": [
    "end = time.time()\n",
    "print(f\"The model took {(end - start) // 60} minutes to train.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"image_splits/split_0\")\n",
    "example1 = df1.image_matrix.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<unknown>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m~/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3251\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  Input \u001b[1;32mIn [44]\u001b[0m in \u001b[1;35m<module>\u001b[0m\n    m = ast.literal_eval(example1) ### convert the dict as str to  dict\n",
      "  File \u001b[1;32m/usr/lib/python3.8/ast.py:59\u001b[0m in \u001b[1;35mliteral_eval\u001b[0m\n    node_or_string = parse(node_or_string, mode='eval')\n",
      "\u001b[0;36m  File \u001b[0;32m/usr/lib/python3.8/ast.py:47\u001b[0;36m in \u001b[0;35mparse\u001b[0;36m\u001b[0m\n\u001b[0;31m    return compile(source, filename, mode, flags,\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m<unknown>:1\u001b[0;36m\u001b[0m\n\u001b[0;31m    [[[255 255 255]\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# d = dict(enumerate(k.flatten(), 1))\n",
    "# d = str(d) ## dump as string  (pickle and other packages parse the dump as bytes)\n",
    "\n",
    "m = ast.literal_eval(example1) ### convert the dict as str to  dict\n",
    "\n",
    "m = np.fromiter(m.values(), dtype=float) ## convert m to nparray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([[255, 255, 255], [255, 255, 255], [255, 255, 255], Ellipsis, [255, 255, 255], [255, 255, 255], [255, 255, 255]]),\n",
       "       list([[255, 255, 255], [255, 255, 255], [255, 255, 255], Ellipsis, [255, 255, 255], [255, 255, 255], [255, 255, 255]]),\n",
       "       list([[255, 255, 255], [255, 255, 255], [255, 255, 255], Ellipsis, [255, 255, 255], [255, 255, 255], [255, 255, 255]]),\n",
       "       Ellipsis,\n",
       "       list([[255, 255, 255], [255, 255, 255], [255, 255, 255], Ellipsis, [255, 255, 255], [255, 255, 255], [255, 255, 255]]),\n",
       "       list([[255, 255, 255], [255, 255, 255], [255, 255, 255], Ellipsis, [255, 255, 255], [255, 255, 255], [255, 255, 255]]),\n",
       "       list([[255, 255, 255], [255, 255, 255], [255, 255, 255], Ellipsis, [255, 255, 255], [255, 255, 255], [255, 255, 255]])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25610/2848097840.py:1: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  np.fromstring(example1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "string size must be a multiple of element size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromstring\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample1\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: string size must be a multiple of element size"
     ]
    }
   ],
   "source": [
    "np.fromstring(example1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
