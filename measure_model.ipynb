{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instructions: run entire notebook after specifying directory variable at the top\n",
    "> model = resnet152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/home/paperspace/Documents/dc-grocery-outlet-brand/image_splits_v2\"\n",
    "directory2 = \"/home/paperspace/Documents/dc-grocery-outlet-brand/image_splits_10_or_less\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torchvision.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils import data\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import random\n",
    "from model import *\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from PIL import Image\n",
    "\n",
    "import pprint, pickle\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(d):\n",
    "    r = []\n",
    "    for root, dirs, files in os.walk(d):\n",
    "        for name in files:\n",
    "            r.append(os.path.join(root, name))\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "4bd4e024-b1ca-4eb7-adf6-4eb8f9110816",
     "kernelId": "4f378984-b18d-4458-aec5-11036b1449fe"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# model = models.resnet34(pretrained=True)\n",
    "model = models.resnet152(pretrained=True) # we do not specify pretrained=True, i.e. do not load default weights\n",
    "# model.load_state_dict(torch.load('XNAS/trained_models/xnas_small_cifar10.t7'), strict=False)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 53)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('UPC-Images-Sample-Labeled.csv').drop(['Short Description', 'ItemNumber', 'SubClass', 'Department', 'class_subclass', 'label'], axis = 1)\n",
    "df.Brand = df.Brand.str.lower()\n",
    "df = df.sort_values(by='Brand', ascending=True)\n",
    "no_dupes_df = df.drop_duplicates(\"ImageList\")\n",
    "brand_df = no_dupes_df[no_dupes_df.Brand.notna()]\n",
    "brands_10_or_less = brand_df.groupby('Brand').filter(lambda subdf: len(subdf) <= 10)['Brand']\n",
    "\n",
    "brand_df.Measure = brand_df.Measure.str.lower()\n",
    "brand_df.Measure = brand_df.Measure.str.replace(' ', '')\n",
    "more_than_10_df = brand_df[~brand_df['Brand'].isin(brands_10_or_less)]\n",
    "\n",
    "\n",
    "measure_to_num = dict(zip(np.unique(brand_df['Measure'].values), np.arange(len(np.unique(brand_df['Measure'].values)))))\n",
    "num_to_measure = dict(zip(np.arange(len(np.unique(brand_df['Measure'].values))), np.unique(brand_df['Measure'].values)))\n",
    "measure_to_num.update(num_to_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(brand_df['Measure'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Size</th>\n",
       "      <th>Measure</th>\n",
       "      <th>Class</th>\n",
       "      <th>Long Description</th>\n",
       "      <th>ImageList</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>167007</th>\n",
       "      <td>ag</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>81</td>\n",
       "      <td>AG 37689 PLUSH MR.&amp; MRS. ELF SILVR</td>\n",
       "      <td>prod/00797648989728.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167006</th>\n",
       "      <td>ag</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>81</td>\n",
       "      <td>AG 37684 PLUSH SANTA/SNOWMAN SILVR</td>\n",
       "      <td>prod/00797648989711.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167008</th>\n",
       "      <td>ag</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>81</td>\n",
       "      <td>AG 39002 TABLE TOP GNOME FIGURE</td>\n",
       "      <td>prod/00797648989735.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167005</th>\n",
       "      <td>ag</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>81</td>\n",
       "      <td>AG 37680 SANTA/SNOWMAN GREETERS</td>\n",
       "      <td>prod/00797648989704.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167004</th>\n",
       "      <td>ag</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>81</td>\n",
       "      <td>AG 27461 TWINKLING ICICLE LIGHTS</td>\n",
       "      <td>prod/00797648989667.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18142</th>\n",
       "      <td>trident</td>\n",
       "      <td>3CT</td>\n",
       "      <td></td>\n",
       "      <td>58</td>\n",
       "      <td>TRIDENT WATERMELON TWIST GUM</td>\n",
       "      <td>prod/00012546011396.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18143</th>\n",
       "      <td>trident</td>\n",
       "      <td>3CT</td>\n",
       "      <td></td>\n",
       "      <td>58</td>\n",
       "      <td>TRIDENT TROPICAL TWIST SUGAR FREE</td>\n",
       "      <td>prod/00012546011389.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44588</th>\n",
       "      <td>vicks</td>\n",
       "      <td>8CT</td>\n",
       "      <td></td>\n",
       "      <td>82</td>\n",
       "      <td>VICKS DAYQUIL COLD/FLU LIQUICAP</td>\n",
       "      <td>prod/00323900038448.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158810</th>\n",
       "      <td>vista</td>\n",
       "      <td>12X11</td>\n",
       "      <td></td>\n",
       "      <td>81</td>\n",
       "      <td>VISTA WALL CALENDAR</td>\n",
       "      <td>prod/00788958701520.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>zyrtec</td>\n",
       "      <td>70CT</td>\n",
       "      <td></td>\n",
       "      <td>82</td>\n",
       "      <td>ZYRTEC 10MG ZYRTEC 10MG ALLERGY TABLE</td>\n",
       "      <td>prod/00300450204707.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>226 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Brand   Size Measure  Class  \\\n",
       "167007  ag                                           81   \n",
       "167006  ag                                           81   \n",
       "167008  ag                                           81   \n",
       "167005  ag                                           81   \n",
       "167004  ag                                           81   \n",
       "...                           ...    ...     ...    ...   \n",
       "18142   trident                    3CT               58   \n",
       "18143   trident                    3CT               58   \n",
       "44588   vicks                      8CT               82   \n",
       "158810  vista                      12X11             81   \n",
       "1301    zyrtec                     70CT              82   \n",
       "\n",
       "                                Long Description                ImageList  \n",
       "167007  AG 37689 PLUSH MR.& MRS. ELF SILVR        prod/00797648989728.jpg  \n",
       "167006  AG 37684 PLUSH SANTA/SNOWMAN SILVR        prod/00797648989711.jpg  \n",
       "167008  AG 39002 TABLE TOP GNOME FIGURE           prod/00797648989735.jpg  \n",
       "167005  AG 37680 SANTA/SNOWMAN GREETERS           prod/00797648989704.jpg  \n",
       "167004  AG 27461 TWINKLING ICICLE LIGHTS          prod/00797648989667.jpg  \n",
       "...                                          ...                      ...  \n",
       "18142   TRIDENT WATERMELON TWIST GUM              prod/00012546011396.jpg  \n",
       "18143   TRIDENT TROPICAL TWIST SUGAR FREE         prod/00012546011389.jpg  \n",
       "44588   VICKS DAYQUIL COLD/FLU LIQUICAP           prod/00323900038448.jpg  \n",
       "158810  VISTA WALL CALENDAR                       prod/00788958701520.jpg  \n",
       "1301    ZYRTEC 10MG ZYRTEC 10MG ALLERGY TABLE     prod/00300450204707.jpg  \n",
       "\n",
       "[226 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "more_than_10_df[more_than_10_df['Measure'] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_make_image_splits(file):\n",
    "    \"\"\"\n",
    "        given a .pkl file, returns a 3D numpy array\n",
    "    \"\"\"\n",
    "\n",
    "    pkl_file = open(file, 'rb')\n",
    "\n",
    "    data1 = pickle.load(pkl_file)\n",
    "    pkl_file.close()\n",
    "\n",
    "    return data1\n",
    "\n",
    "d = read_make_image_splits(directory + \"/split_0.pkl\")\n",
    "a = d[0, -1]\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "64b15a06-9d16-4d68-a130-7c6c2d4298ab",
     "kernelId": "4f378984-b18d-4458-aec5-11036b1449fe"
    }
   },
   "outputs": [],
   "source": [
    "def test_model(model, generator):\n",
    "    pbar = tqdm(val_generator)\n",
    "    running_corrects = 0\n",
    "    for step, batch in enumerate(pbar):\n",
    "        model.eval()\n",
    "      # inputs = inputs.to(device)\n",
    "      # labels = labels.to(device)\n",
    "        inputs, labels = batch\n",
    "        inputs = inputs.to(torch.float)\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "      # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "      # forward\n",
    "      # track history if only in train\n",
    "      # with torch.set_grad_enabled(phase == 'train'):\n",
    "      \n",
    "    \n",
    "      \n",
    "      #print(tuple(images)[0])\n",
    "      # print(labels)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            # print(preds)\n",
    "      \n",
    "    epoch_acc = running_corrects / len(val)\n",
    "    return epoch_acc.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "5a091f1f-ae6c-4be7-bccc-ed41441e1497",
     "kernelId": "4f378984-b18d-4458-aec5-11036b1449fe"
    }
   },
   "source": [
    "## train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToTensor()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchvision.transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file):\n",
    "    \"\"\"\n",
    "        given a file, returns generators for training, test, and validation\n",
    "    \"\"\"\n",
    "    \n",
    "    def read_make_image_splits(file):\n",
    "        \"\"\"\n",
    "            given a .pkl file, returns a 3D numpy array\n",
    "        \"\"\"\n",
    "\n",
    "        pkl_file = open(file, 'rb')\n",
    "\n",
    "        data1 = pickle.load(pkl_file)\n",
    "        pkl_file.close()\n",
    "\n",
    "        return data1\n",
    "    \n",
    "    df = pd.DataFrame(read_make_image_splits(file), columns=[\"brand\", \"size\", \"measure\", \"class\", \"long_description\", \"ImageList\", \"image_matrix\", \"image_tensor\"])\n",
    "    df = df.dropna()\n",
    "    df['measure'] = df['measure'].str.lower()\n",
    "    df['measure'] = df['measure'].str.replace(' ', '')\n",
    "    df['measure'] = df[['measure']].replace(measure_to_num)['measure']\n",
    "\n",
    "    df_brand = df[[\"image_tensor\", \"measure\"]]\n",
    "    # df_brand[\"image_tensor\"] = df_brand[\"image_matrix\"].map(lambda img: transforms.Resize((224, 224))(torch.permute(torch.tensor(img), (2, 0, 1))))\n",
    "    # df_brand.drop(\"image_matrix\", axis=1, inplace=True)\n",
    "    \n",
    "    # ske = LabelEncoder()\n",
    "    # df_brand.brand = df_brand.brand.str.lower()\n",
    "    # df_brand.brand = df_brand.brand.str.replace(' ', '')\n",
    "    # df_brand[\"brand\"] = df_brand[[\"brand\"]].replace(brand_to_num)[\"brand\"]\n",
    "    # df_brand.brand = df_brand[\"brand\"].astype(int)\n",
    "    \n",
    "    # print(len(df_brand.brand.unique()))\n",
    "    train = list(map(list, zip(df_brand[\"image_tensor\"].values, df_brand[\"measure\"].values)))\n",
    "    \n",
    "    random.shuffle(train)\n",
    "    val_split = int(len(train)*0.8)\n",
    "    test_split = int(len(train)*0.9)\n",
    "    val = train[val_split:test_split]\n",
    "    test = train[test_split:]\n",
    "    train = train[:val_split]\n",
    "    # print(train[0])\n",
    "    # print(train[0][0])\n",
    "    # train, val = train_test_split(train, test_size=0.2)\n",
    "    # train, test = train_test_split(train, test_size=0.1)\n",
    "\n",
    "    train_generator = data.DataLoader(train, batch_size=64)\n",
    "    test_generator = data.DataLoader(test, batch_size=64)\n",
    "    val_generator = data.DataLoader(val, batch_size=64)\n",
    "    \n",
    "    return train_generator, test_generator, val_generator, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, save_path, epoch):\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'epoch' : epoch\n",
    "    }, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(model, optimizer, load_path):\n",
    "    checkpoint = torch.load(load_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    return model, optimizer, epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "cb034852-b0b2-44f4-b06c-fa4521d4ac33",
     "kernelId": "4f378984-b18d-4458-aec5-11036b1449fe"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "----------\n",
      "File 0/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 5.651417660713196: 100%|██████████████| 10/10 [00:03<00:00,  3.19it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  5.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.6233766078948975\n",
      "\n",
      "File 1/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 3.119747245311737: 100%|██████████████| 10/10 [00:03<00:00,  3.06it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.649350643157959\n",
      "\n",
      "File 2/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 2.5684202551841735: 100%|█████████████| 10/10 [00:03<00:00,  3.11it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.5844155550003052\n",
      "\n",
      "File 3/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 1.7226662933826447: 100%|█████████████| 10/10 [00:03<00:00,  2.96it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.5974025726318359\n",
      "\n",
      "File 4/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 2.2242927312850953: 100%|█████████████| 10/10 [00:03<00:00,  3.05it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  5.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.5844155550003052\n",
      "\n",
      "File 5/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 1.9497422099113464: 100%|█████████████| 10/10 [00:03<00:00,  3.11it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.649350643157959\n",
      "\n",
      "File 6/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 1.7029141545295716: 100%|█████████████| 10/10 [00:03<00:00,  3.08it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.5974025726318359\n",
      "\n",
      "File 7/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 1.8140720844268798: 100%|█████████████| 10/10 [00:03<00:00,  3.10it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  5.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.6363636255264282\n",
      "\n",
      "File 8/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 1.6788956284523011: 100%|█████████████| 10/10 [00:03<00:00,  3.20it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  5.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.7402597665786743\n",
      "\n",
      "File 9/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 1.988192081451416: 100%|██████████████| 10/10 [00:03<00:00,  3.06it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.6103895902633667\n",
      "\n",
      "File 10/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 2.2714237372080484:  60%|████████▍     | 6/10 [00:02<00:01,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of dims dont match in permute\n",
      "File 11/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 1.5517724394798278: 100%|█████████████| 10/10 [00:03<00:00,  3.08it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.649350643157959\n",
      "\n",
      "File 12/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 1.5414624895368303:  70%|█████████▊    | 7/10 [00:02<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of dims dont match in permute\n",
      "File 13/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 1.682902491092682: 100%|██████████████| 10/10 [00:03<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  4.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.649350643157959\n",
      "\n",
      "File 14/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 1.6195969700813293: 100%|█████████████| 10/10 [00:04<00:00,  2.11it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.6233766078948975\n",
      "\n",
      "File 15/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 2.0190543651580812: 100%|█████████████| 10/10 [00:03<00:00,  3.26it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  5.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.5974025726318359\n",
      "\n",
      "File 16/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 2.173259937763214: 100%|██████████████| 10/10 [00:05<00:00,  1.80it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.5974025726318359\n",
      "\n",
      "File 17/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 2.033553194999695: 100%|██████████████| 10/10 [00:05<00:00,  1.81it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.6103895902633667\n",
      "\n",
      "File 18/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 2.011916697025299: 100%|██████████████| 10/10 [00:04<00:00,  2.03it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.7662337422370911\n",
      "\n",
      "File 19/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 2.131421148777008: 100%|██████████████| 10/10 [00:05<00:00,  1.75it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.5714285969734192\n",
      "\n",
      "File 20/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 1.9051010251045226: 100%|█████████████| 10/10 [00:05<00:00,  1.86it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  5.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.6233766078948975\n",
      "\n",
      "File 21/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 1.8763115525245666: 100%|█████████████| 10/10 [00:06<00:00,  1.60it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  6.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.649350643157959\n",
      "\n",
      "File 22/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 1.7260123372077942: 100%|█████████████| 10/10 [00:05<00:00,  1.79it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.5194805264472961\n",
      "\n",
      "File 23/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 1.6956799983978272: 100%|█████████████| 10/10 [00:05<00:00,  1.94it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  5.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.5714285969734192\n",
      "\n",
      "File 24/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 1.9783524930477143: 100%|█████████████| 10/10 [00:04<00:00,  2.33it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.6623376607894897\n",
      "\n",
      "File 25/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 1.6126747727394104: 100%|█████████████| 10/10 [00:05<00:00,  1.87it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.7532467246055603\n",
      "\n",
      "File 26/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 1.4725938856601715: 100%|█████████████| 10/10 [00:05<00:00,  1.72it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.7532467246055603\n",
      "\n",
      "File 27/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 1.7508223712444306: 100%|█████████████| 10/10 [00:06<00:00,  1.43it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.6363636255264282\n",
      "\n",
      "File 28/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 1.7672715425491332: 100%|█████████████| 10/10 [00:05<00:00,  1.79it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.6883116960525513\n",
      "\n",
      "File 29/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 1.8954692006111145: 100%|█████████████| 10/10 [00:06<00:00,  1.43it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.6623376607894897\n",
      "\n",
      "File 30/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 2.3467404961586: 100%|████████████████| 10/10 [00:04<00:00,  2.05it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  5.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.6363636255264282\n",
      "\n",
      "File 31/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 1.5648075222969056: 100%|█████████████| 10/10 [00:06<00:00,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  6.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.6363636255264282\n",
      "\n",
      "File 32/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 1.9457224011421204: 100%|█████████████| 10/10 [00:04<00:00,  2.00it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.701298713684082\n",
      "\n",
      "File 33/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 1.6270308136940002: 100%|█████████████| 10/10 [00:03<00:00,  2.53it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  4.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.5064935088157654\n",
      "\n",
      "File 34/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 1.824999213218689: 100%|██████████████| 10/10 [00:04<00:00,  2.09it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.7142857313156128\n",
      "\n",
      "File 35/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 1.9760784268379212: 100%|█████████████| 10/10 [00:04<00:00,  2.46it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  5.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.5454545617103577\n",
      "\n",
      "File 36/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 1.806699812412262: 100%|██████████████| 10/10 [00:05<00:00,  1.82it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  6.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.649350643157959\n",
      "\n",
      "File 37/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 1.9113112807273864: 100%|█████████████| 10/10 [00:04<00:00,  2.16it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.6103895902633667\n",
      "\n",
      "File 38/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 1.7046826243400575: 100%|█████████████| 10/10 [00:07<00:00,  1.40it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.5974025726318359\n",
      "\n",
      "File 39/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 1.434643816947937: 100%|██████████████| 10/10 [00:05<00:00,  1.95it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.6623376607894897\n",
      "\n",
      "File 40/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 2.0415789127349853: 100%|█████████████| 10/10 [00:04<00:00,  2.00it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.5324675440788269\n",
      "\n",
      "File 41/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 1.6545773208141328: 100%|█████████████| 10/10 [00:05<00:00,  1.87it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.7272727489471436\n",
      "\n",
      "File 42/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 1.7859725832939148: 100%|█████████████| 10/10 [00:05<00:00,  1.77it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  5.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.6883116960525513\n",
      "\n",
      "File 43/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 1.8216983556747437: 100%|█████████████| 10/10 [00:05<00:00,  1.93it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.6883116960525513\n",
      "\n",
      "File 44/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 1.5687450230121613: 100%|█████████████| 10/10 [00:04<00:00,  2.00it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.6103895902633667\n",
      "\n",
      "File 45/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 1.9377245903015137: 100%|█████████████| 10/10 [00:05<00:00,  1.94it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.6883116960525513\n",
      "\n",
      "File 46/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 1.652606439590454: 100%|██████████████| 10/10 [00:04<00:00,  2.12it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.6363636255264282\n",
      "\n",
      "File 47/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 1.588387906551361: 100%|██████████████| 10/10 [00:04<00:00,  2.16it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.701298713684082\n",
      "\n",
      "File 48/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 1.6692914009094237: 100%|█████████████| 10/10 [00:04<00:00,  2.23it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.6753246784210205\n",
      "\n",
      "File 49/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 2.1105664730072022: 100%|█████████████| 10/10 [00:04<00:00,  2.12it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.701298713684082\n",
      "\n",
      "Epoch 2/1000\n",
      "----------\n",
      "File 0/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 4.092386567592621: 100%|██████████████| 10/10 [00:05<00:00,  1.84it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.5714285969734192\n",
      "\n",
      "File 1/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 2.7201318025588987: 100%|█████████████| 10/10 [00:05<00:00,  1.90it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.6623376607894897\n",
      "\n",
      "File 2/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 2.6209794878959656: 100%|█████████████| 10/10 [00:04<00:00,  2.14it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.6623376607894897\n",
      "\n",
      "File 3/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 1.726946759223938: 100%|██████████████| 10/10 [00:04<00:00,  2.25it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  4.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.6363636255264282\n",
      "\n",
      "File 4/50\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [37]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m file_num \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 28\u001b[0m     train_generator, test_generator, val_generator, val \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     pbar \u001b[38;5;241m=\u001b[39m tqdm(train_generator)\n\u001b[1;32m     31\u001b[0m     running_avg_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36mpreprocess\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m     14\u001b[0m     pkl_file\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data1\n\u001b[0;32m---> 18\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mread_make_image_splits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrand\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeasure\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlong_description\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImageList\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     19\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[1;32m     20\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeasure\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeasure\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlower()\n",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36mpreprocess.<locals>.read_make_image_splits\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m    given a .pkl file, returns a 3D numpy array\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     11\u001b[0m pkl_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m data1 \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpkl_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m pkl_file\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data1\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/storage.py:160\u001b[0m, in \u001b[0;36m_load_from_bytes\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    157\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_new_using_fd(size)\n\u001b[0;32m--> 160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_from_bytes\u001b[39m(b):\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mload(io\u001b[38;5;241m.\u001b[39mBytesIO(b))\n\u001b[1;32m    164\u001b[0m _StorageBase\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m=\u001b[39m _type  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "best_acc = 0\n",
    "losses = []\n",
    "scores = []\n",
    "best_model_wts = None\n",
    "model_path = 'measure_model.pt'\n",
    "start = time.time()\n",
    "\n",
    "files = list_files(directory2)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "# model, optimizer, model_epoch = load_checkpoint(model, optimizer, model_path)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "    print('-' * 10)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    # model, optimizer = load_checkpoint(model, optimizer, model_path)\n",
    "    file_num = 0\n",
    "    \n",
    "    \n",
    "    for file in files:\n",
    "        print('File {}/{}'.format(file_num, len(files)))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        file_num += 1\n",
    "        try:\n",
    "            train_generator, test_generator, val_generator, val = preprocess(file)\n",
    "\n",
    "            pbar = tqdm(train_generator)\n",
    "            running_avg_loss = 0\n",
    "            for step, batch in enumerate(pbar):\n",
    "                model.train()\n",
    "                inputs, labels = batch\n",
    "                inputs = inputs.to(torch.float)\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                # with torch.set_grad_enabled(phase == 'train'):\n",
    "                '''images = []\n",
    "                for image_path in inputs:\n",
    "                    img = Image.open(os.path.join(image_dir, image_path))\n",
    "                    images.append(transforms.ToTensor()(img))'''\n",
    "\n",
    "                #print(tuple(images)[0])\n",
    "                # print(labels)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                # _, preds = torch.max(outputs, 1)\n",
    "                # print(labels)\n",
    "                # print(outputs)\n",
    "                # print(outputs.shape)\n",
    "                loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "                # print(loss)\n",
    "                # backward + optimize only if in training phase\n",
    "                loss.backward()\n",
    "                # print(loss)\n",
    "                # pbar.set_description(str(loss.item()))\n",
    "                optimizer.step()\n",
    "                # avg_loss = (avg_loss + loss.item()) / (step + 1)\n",
    "                running_avg_loss += loss.item()\n",
    "                pbar.set_description(\"Avg Loss: \" + str(running_avg_loss / (step + 1)))\n",
    "\n",
    "                # statistics\n",
    "                # running_loss += loss.item() * inputs.size(0)\n",
    "                # running_corrects += torch.sum(preds == labels.data)\n",
    "                # scheduler.step()\n",
    "\n",
    "                 #NOTE: need to fix validation because this val_generator only covers 1 file, not all 50   \n",
    "        except(RuntimeError):\n",
    "            print('number of dims dont match in permute')\n",
    "            continue\n",
    "            \n",
    "        epoch_acc = test_model(model, val_generator)\n",
    "        if epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        print(\"validation accuracy:\", epoch_acc)\n",
    "        scores.append(epoch_acc)\n",
    "        #losses.append(running_avg_loss / len(train_generator))\n",
    "        print()\n",
    "       \n",
    "    save_checkpoint(model, optimizer, model_path, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "937a4285-061a-44cf-b15b-8284ea48b336",
     "kernelId": "4f378984-b18d-4458-aec5-11036b1449fe"
    }
   },
   "outputs": [],
   "source": [
    "end = time.time()\n",
    "print(f\"The model took {(end - start) // 60} minutes to train.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = preprocess(\"image_splits_v2/split_0.pkl\")\n",
    "tqdm(ex[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = dict(enumerate(k.flatten(), 1))\n",
    "# d = str(d) ## dump as string  (pickle and other packages parse the dump as bytes)\n",
    "\n",
    "m = ast.literal_eval(example1) ### convert the dict as str to  dict\n",
    "\n",
    "m = np.fromiter(m.values(), dtype=float) ## convert m to nparray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.fromstring(example1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
